\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{pythontex}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{titling}
\usepackage{amsmath}

\title{Using Machine Learning to Predict Typing Speed\vspace{-3em}}
\author{} % Anonymous because IB
\date{}

\newcommand{\code}[1]{\texttt{#1}}

\newenvironment{textexamples}
  {\medskip\par\setlength{\parindent}{0pt}}
  {\par\medskip}

\graphicspath{{assets/}}

\begin{document}

\maketitle

\section*{Introduction}

One of my hobbies is competitive typing, where I compete with my friends to type a text as quickly as possible. I often use a website called TypeRacer, where your goal is to drive a racecar to the finish line, and the position of your racecar is determined by how many words you've typed correctly in the quote:

\begin{figure}[hbt!]
	\caption{A screenshot of a typing competition on the website \textit{TypeRacer}}
	\includegraphics[width=\textwidth]{typeracer.png}
\end{figure}

Your score is a measurement of your average typing speed at the end of the race. Typing speed is measured in the units "words per minute" ("wpm" for short), and each word is defined as five characters.

In TypeRacer, your typing speed determines the types of texts you'll be presented with: a lower typing speed gives you easier texts, while a higher typing speed gives you more difficult texts:

\begin{figure}[hbt!]
	\caption{Two different possible texts in TypeRacer. On the left, an easy text, and on the right, a more difficult text.}
	\includegraphics[width=0.5\textwidth]{easy-text.png}
	\includegraphics[width=0.5\textwidth]{hard-text.png}
\end{figure}


However, not all texts are created equal. Some texts are harder to type than others, whether it's from having longer, more complex words, frequent capital letters, numbers, etc.

Predicting the difficulty of a text is useful. For example, the typing site that I practice on, TypeRacer, will display different sets of texts depending . For example, these are two quotes that can appear in a TypeRacer race:


Even though Quote 1 is shorter than Quote 2, the difficult word at the start of Quote 1 makes it significantly more difficult to type.

Currently, the way TypeRacer classifies the difficulty of a newly added quote is through . Each player has an average typing speed that is calculated based on their best scores for each quote, and if the

At first, I considered using the length of the text might be to use the length of the text in determining its difficulty. While this works for the two texts shown in Figure 1, it's not a flawless approach. For example, the following two texts are possible texts you can encounter in TypeRacer:

\begin{textexamples}
	\textbf{Text 1}: Supercalifragilisticexpialidocious is Vielle's favorite word to type on TypeRacer.
	\textbf{Text 2}: For someone who was never meant for this world, I must confess I'm suddenly having a hard time leaving it.
\end{textexamples}

Even though Text 1 has fewer characters than Text 2, it is still considerably more difficult to type because of the complex first word.

, but there are many more characteristics of words that affect the speed at which they are typed. For example, one of these characteristics is the fingers you use to type the word.

\includegraphics{finger-map.png}

Using this standard finger map, when typing the word \texttt{mummy} on the QWERTY keyboard, you would exclusively use your right index finger to type the entire word, making it significantly slower to type compared to a word like \texttt{there}, which doesn't involve using the same finger to type two consecutive letters.

\begin{textexamples}
\end{textexamples}

The characteristics of how difficult a word is to type extends beyond these two examples, and each characteristic has a different amount of influence on how quickly I type the word. In order to determine the significance of these various characteristics in the difficulty of a word, machine learning can be applied.

\section*{Applying Machine Learning}

\begin{align*}
\text{Difficulty} = w_1 * (\text{Feature 1}) + w_2 * (\text{Feature 2}) + ... + \text{Bias}
\end{align*}

For example, if there are two features that influence the difficulty of a word which are the length of the word and the number of capital letters in the word, then the equation would become:

\begin{align*}
\text{Difficulty} = w_{\text{word length}} * (\text{word length}) + w_{\text{capital letters}} * (\text{\# of capital letters}) + \text{Bias}
\end{align*}



If we measure the difficulty of a word as the speed at which the word is typed (i.e. in the units words per minute), then we arrive at an equation similar to the following:

Since TypeRacer's API doesn't provide data that's sufficiently

\section{Features}

% Script to find average word length of sentences
% \begin{noindent}
\begin{pycode}
import numpy as np

first_sentence = "Someverylongandhardtotypeword and a lot of tiny and short words that are more easy to type."
second_sentence = "Generally, this sentence contains longer and more complex words, but is overall easier to type."

def get_avg_word_length(sentence: str):
	return np.mean([len(word) for word in sentence.split(' ')])

def get_avg_word_length_formatted(sentence: str):
	return "{:.2f}".format(get_avg_word_length(sentence))
\end{pycode}
% \end{noindent}

In a quote, there are often certain parts of the quote that are harder than others. Thus, features that take into account averages like the average word length might not accurately reflect a quote. This problem is demonstrated by the following example:

\medskip

\begin{textexamples}
	\textbf{Quote 1:} \py{first_sentence}
	\newline
	Average word length: \py{get_avg_word_length_formatted(first_sentence)} words

	\smallskip

	\textbf{Quote 2:} \py{second_sentence}
	\newline
	Average word length: \py{get_avg_word_length_formatted(second_sentence)} words
\end{textexamples}

\medskip

In the above example, even though Quote 1, has a long word that on its own would be much harder to type, the average word length of the quote overall is.

One possible solution would be analyze each word individually, independent of the others. Then, to predict an overall score, we would sum up the individual speed of each word. However, this approach doesn't account for cases where the words before and after influence the speed at which the word is typed. Consider the following example

\medskip

\begin{textexamples}
	\textbf{Quote 1:} he HAS a keyboard
	\textbf{Quote 2:} he has a keyboard
\end{textexamples}

In the first quote, to type \code{HAS}, I need to use my left pinky finger to hold down the shift key while I press the \code{;} key on using my right hand. Then, to type the letter \code{a}, I need to lift up my pinky finger and move it to the /

% \begin{noindent}
\begin{pycode}
row_number = 0

quote_1_wpm = [98, 101, 94, 122, 86]
quote_1_avg = np.mean(quote_1_wpm)

quote_2_wpm = [119, 143, 120, 140, 115]
quote_2_avg = np.mean(quote_2_wpm)

def get_table_1_row(index: int):
	global row_number
	row_number += 1
	return f"\\\\\\hline \n {row_number} & {quote_1_wpm[index]} & {quote_2_wpm[index]}"
\end{pycode}
% \end{noindent}

\begin{tabularx}{\textwidth}{|X|X|X|}
	\hline

	Trial \# & Quote 1 WPM      & Quote 2 WPM

	\py{get_table_1_row(0)}
	\py{get_table_1_row(1)}
	\py{get_table_1_row(2)}
	\py{get_table_1_row(3)}
	\py{get_table_1_row(4)}

	\\\hline
	Average  & \py{quote_1_avg} & \py{quote_2_avg}
	\\\hline
\end{tabularx}

Thus, analyzing the WPM of typing individual words isn't enough.

Instead, we can combine the two above approaches and analyze pairs of words instead, as the speed of a word usually depends on the word before it, since that's usually the word that determines the final locations of finger placements before typing the next word. For example, the following quote:

The quick brown fox jumps

Would be broken down into the following word pairs:

The quick
quick brown
brown fox
fox jumps

Then, using the logs from the race data, we then calculate the wpm of typing each of these word pairs. A dummy result might be:

The quick - 168 wpm
quick brown - 163 wpm
brown fox - 164 wpm
fox jumps - 182 wpm

This process is repeated for every quote and the results are saved. Then, we identify features in each word pair and feed the data into our machine learning algorithm such that it would be able to predict the speed of typing a certain word pair.

To find the average, you first assign the first value to a wpm that's know (i.e. you know how fast typing the individual word would be. This would be another machine learning algorithm of its own: predicting how fast you would type a word if it was the first word of a sentence. I have to use all my quotes but it might not be the most complete data set.).

% \begin{noindent}
\begin{pycode}
features = """
	- How many double letters the word has (double letters are slower to type)
	- How many characters the word has
	- Can't measure every letter combination because there's not enough data (e.g. if I wanted to predict how fast I'd type an abbreviation like "nvm", I don't have enough data on words that have the "nv" or "vm" combination).
	-
"""
\end{pycode}
% \end{noindent}

\begin{itemize}
	\item The numbers of words in the quote
	\item The individual word frequencies
	\item
\end{itemize}

For the purpose of this analysis, we won't be taking into account word accuracy. This is because accuracy is fairly random: just because I type a word wrong in one race doesn't mean that I usually type that word wrong, and just because I've never typed a word wrong doesn't mean I've mastered it. To eliminate this noise, we'll be disregarding mistyped words from the dataset.

\end{document}